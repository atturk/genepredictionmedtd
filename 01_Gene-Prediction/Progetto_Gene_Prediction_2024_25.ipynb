{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRVrI29DRzVe"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# MODIFICARE QUESTA SEZIONE INSERENDO I PROPRI DATI #\n",
        "#####################################################\n",
        "\n",
        " # identificativo del gruppo da verificare nel file excel\n",
        "group_id = 31\n",
        "\n",
        " # nome della cartella Google Drive dove salvare i file\n",
        "cartella_drive = \"CorsoBioinformatica\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqKw66NPRUwR",
        "outputId": "980a5834-81aa-4271-a5ac-9dae4be562b4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\n",
            "Collecting git+https://github.com/Benjamin-Lee/CodonAdaptationIndex.git\n",
            "  Cloning https://github.com/Benjamin-Lee/CodonAdaptationIndex.git to /tmp/pip-req-build-pacm1ujl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Benjamin-Lee/CodonAdaptationIndex.git /tmp/pip-req-build-pacm1ujl\n",
            "  Resolved https://github.com/Benjamin-Lee/CodonAdaptationIndex.git to commit b6e017a92c58829f6a5aec8c26a21262bc2a6610\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from CAI==1.0.5.dev3+gb6e017a) (1.14.1)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (from CAI==1.0.5.dev3+gb6e017a) (1.85)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from CAI==1.0.5.dev3+gb6e017a) (8.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython->CAI==1.0.5.dev3+gb6e017a) (1.26.4)\n",
            "Building wheels for collected packages: CAI\n",
            "  Building wheel for CAI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for CAI: filename=CAI-1.0.5.dev3+gb6e017a.d20250315-py3-none-any.whl size=7850 sha256=4aff8fea7ea1993d3298c06f4502e67ed298d0f6df17f72261dec41cee8204d1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-inl5f6t4/wheels/b3/07/05/fe24a5e008e49d2d8124e99d1bbe93c3d7115cdb4cfd1cb1d4\n",
            "Successfully built CAI\n",
            "Installing collected packages: CAI\n",
            "  Attempting uninstall: CAI\n",
            "    Found existing installation: CAI 1.0.5.dev3+gb6e017a.d20250315\n",
            "    Uninstalling CAI-1.0.5.dev3+gb6e017a.d20250315:\n",
            "      Successfully uninstalled CAI-1.0.5.dev3+gb6e017a.d20250315\n",
            "Successfully installed CAI-1.0.5.dev3+gb6e017a.d20250315\n"
          ]
        }
      ],
      "source": [
        "# Installazione moduli aggiuntivi\n",
        "!pip install biopython\n",
        "!pip install git+https://github.com/Benjamin-Lee/CodonAdaptationIndex.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4ZMH5d-RWxQ"
      },
      "outputs": [],
      "source": [
        "# Importazione moduli\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import regex\n",
        "import Bio\n",
        "import Bio.SeqIO\n",
        "from bisect import bisect_left\n",
        "import pickle\n",
        "from CAI import CAI\n",
        "from Bio.Blast import NCBIWWW, NCBIXML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7O3c9CoFo7Y"
      },
      "outputs": [],
      "source": [
        "# CARICAMENTO DELLA SEQUENZA FASTA\n",
        "# scaricare il file\n",
        "# siloe.dimes.unical.it/~fab/group_<group_id>_seq.fasta\n",
        "!wget -q https://siloe.dimes.unical.it/~fab/MedicinaTD/group_{group_id}_seq.fasta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ricerca delle ORF sulla sequenza (parte del prof)\n",
        "L'oggetto di classe match prende in input\n",
        "\n",
        "\n",
        "*   string: la sequenza iniziale contenente tutti i potenziali geni\n",
        "*   start: posizione iniziale\n",
        "*   stop: posizione finale\n",
        "\n",
        "\n",
        "\n",
        "Il metodo **group** restituisce la sottosequenza (singolo gene). Il metodo **span** restituisce una tupla con posizione iniziale e posizione finale"
      ],
      "metadata": {
        "id": "QGgnnc_iHUoq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjdRCvCeSmWH"
      },
      "outputs": [],
      "source": [
        "# RICERCA DELLE ORF\n",
        "# orf_iter restituisce un iteratore sulle orf\n",
        "# le modalità d'uso sono equivalenti al find_iter di regex\n",
        "\n",
        "class Match:\n",
        "\tdef __init__(self, string, start, stop):\n",
        "\t\tself.string = string\n",
        "\t\tself.start_pos = start\n",
        "\t\tself.stop_pos = stop\n",
        "\t\tself._group0 = string[start:stop]\n",
        "\tdef group(self):\n",
        "\t\treturn self._group0\n",
        "\tdef span(self):\n",
        "\t\treturn (self.start_pos, self.stop_pos)\n",
        "\tdef __repr__(self):\n",
        "\t\treturn f\"<Match object; span={self.span()}, match='{self.group()}'>\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La funzione `orf_iter `\n",
        "1. crea una lista vuota con i codoni di stop\n",
        "2. usa una stringa regex per trovare i codoni di stop nella sequenza e per ogni stop trovato appende aggiunge la posizione iniziale alla lista\n",
        "3. usa una stringa regex per trovare i codoni di start, poi con un ciclo while cerca il primo stop ad una distanza di codoni multiplo di 3\n",
        "4. dato che alla fine usa yield, restituisce un oggetto generatore che contiene i match, sul quale poi dovremo iterare con un ciclo"
      ],
      "metadata": {
        "id": "dw_XQedMPlCq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p87BswT7THqR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def orf_iter(sequence):\n",
        "\t# Cerco tutti i codoni di stop e salvo il punto di partenza\n",
        "\tstops = []\n",
        "\tfor stop in regex.finditer(r\"TAA|TAG|TGA\", sequence):\n",
        "\t\tstops.append(stop.span()[0])\n",
        "\t# Itero sugli start\n",
        "\tfor start in regex.finditer(r\"ATG\", sequence):\n",
        "\t\t# cerco il primo stop con valore di distanza multiplo di 3\n",
        "\t\tpos_start = start.span()[0]\n",
        "\t\tpos_stop = bisect_left(stops, pos_start + 3)\n",
        "\n",
        "\t\twhile (pos_stop < len(stops)) and ((stops[pos_stop] - pos_start) % 3 != 0):\n",
        "\t\t\tpos_stop = pos_stop + 1\n",
        "\t\tif pos_stop < len(stops):\n",
        "\t\t\tyield Match(sequence, pos_start, stops[pos_stop])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gene prediction"
      ],
      "metadata": {
        "id": "MAcWsTnfU4R-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questa parte\n",
        "- carico la sequenza (è un file fasta e qui ho usato la funzione parse del modulo SeqIO di biopython per ottenere la sequenza).\n",
        "- creo il df con i risultati\n",
        "- calcolo anche le frequenze di CG in tutta la sequenza"
      ],
      "metadata": {
        "id": "kzj65Z5vgU8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#caricamento sequenza\n",
        "seq = next(Bio.SeqIO.parse(f\"group_31_seq.fasta\", \"fasta\")).seq\n",
        "#setup df\n",
        "results = pd.DataFrame(columns=[\"ORFpos\",\"Coding\",\"BLAST\"])\n",
        "\n",
        "# Calcolo frequenze CG in tutta la sequenza\n",
        "exp_cpg = seq.count(\"C\")/len(seq) * seq.count(\"G\")/len(seq)"
      ],
      "metadata": {
        "id": "Hf9U7EgXgVKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definizioni funzioni per sensori di segnale\n",
        "- tatabox: controlla se è presente un tatabox con una stringa regex\n",
        "- inr: controlla se è presente un iniziatore con una stringa regex\n",
        "- cpg: le isole cpg sono regioni specifiche del DNA ricche di nucleotidi CG (dove una C è seguita direttamente da una G). Sono definite da criteri specifici\n",
        "  - localizzate a monte della sequenza codificante\n",
        "  - lunghezza > 200 basi\n",
        "  - contenuto GC > 0,5\n",
        "  - rapporto CpG osservato/atteso > 0,6\n",
        "- sequenza di Kozak: una sequenza consenso che circonda il codone di start (ATG) negli eucarioti"
      ],
      "metadata": {
        "id": "N3oAhgNzatrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tatabox(seq):\n",
        "    if regex.search(r\"TATA[AT]A[AT]\", str(seq)):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def inr(seq):\n",
        "    if regex.search(r\"[CT][CT]A[AGCT][AT][CT][CT]\", str(seq)):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def cpg(seq, cpg_tot):\n",
        "    #genero una sottosequenza a monte di quella coficante (3000 bp prima)\n",
        "    seq_monte = str(seq[orf.span()[0]-3000:orf.span()[0]])\n",
        "    #contenuto G e G\n",
        "    GC_monte = len(regex.findall(r\"[GC]\", seq_monte))/3000\n",
        "    #per prima cosa la frequenza deve essere superiore a 0.5\n",
        "    if GC_monte > 0.5:\n",
        "        #rapporto osservato/atteso\n",
        "            obs_CG = seq_monte.count(\"CG\")/3000\n",
        "            #inoltre il rapporto osservato(nella orf)/atteso(in tutta la sequenza) deve essere maggiore di 0.6\n",
        "            if obs_CG/cpg_tot > 0.6:\n",
        "                #se è così aggiunto 1 punto\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def kozak(seq):\n",
        "    if regex.search(r\"[AG]CCATGG\", str(seq)):\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "csNz1GMiVBkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definizione di funzioni per sensori di contenuto\n",
        "- in generale nelle regioni codificanti il contenuto di GC varia da 0,45 a 0,65\n",
        "- CAI (codon adaptability index): nelle regioni codificanti c'è una preferenza per alcuni codoni rispetto ad altri a parità di amminoacido (codoni sinonimi)\n",
        "  - Es. Serina → TCT, TCC, TCA, TCG, AGT, AGC\n",
        "  - ho usato la funzione CAI() del pacchetto omonimo, che data la sequenza e un file con i pesi dei codoni, genera uno score"
      ],
      "metadata": {
        "id": "wUry4iXxV3bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gc_content(seq):\n",
        "    GC_content = len(regex.findall(r\"[GC]\", str(seq)))/3000\n",
        "    if GC_content > 0.45 and GC_content < 0.65:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def codon_freq(seq):\n",
        "    cai_dict = {\"GCT\": 1.000, \"TTG\": 0.600, \"GCC\": 0.900, \"CTA\": 0.400, \"GCA\": 0.700, \"TTA\": 0.300, \"GCG\": 0.600, \"AAG\": 1.000, \"CGT\": 1.000, \"AAA\": 0.800, \"CGC\": 0.900, \"ATG\": 1.000, \"AGA\": 0.700, \"TTC\": 1.000, \"CGG\": 0.600, \"TTT\": 0.800, \"AGG\": 0.500, \"CCG\": 1.000, \"CGA\": 0.400, \"CCC\": 0.900, \"AAC\": 1.000, \"CCT\": 0.800, \"AAT\": 0.800, \"CCA\": 0.700, \"GAC\": 1.000, \"AGC\": 1.000, \"GAT\": 0.800, \"TCT\": 0.900, \"TGC\": 1.000, \"TCC\": 0.800, \"TGT\": 0.800, \"AGT\": 0.700, \"CAG\": 1.000, \"TCA\": 0.600, \"CAA\": 0.700, \"TCG\": 0.500, \"GAG\": 1.000, \"ACC\": 1.000, \"GAA\": 0.800, \"ACT\": 0.900, \"GGC\": 1.000, \"ACA\": 0.700, \"GGT\": 0.900, \"ACG\": 0.600, \"GGA\": 0.700, \"TGG\": 1.000, \"GGG\": 0.600, \"TAC\": 1.000, \"CAC\": 1.000, \"TAT\": 0.800, \"CAT\": 0.800, \"GTG\": 1.000, \"ATC\": 1.000, \"GTC\": 0.900, \"ATT\": 0.900, \"GTT\": 0.800, \"ATA\": 0.500, \"GTA\": 0.600, \"CTG\": 1.000, \"TAA\": 1.000, \"CTC\": 0.800, \"TGA\": 0.900, \"CTT\": 0.700, \"TAG\": 0.800}\n",
        "    cai_score=CAI(seq, weights=cai_dict)\n",
        "    if cai_score > 0.8:\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "VFetZCqEV25n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funzione per verifica sequenza su BLAST\n",
        "Qui uso la funzione qblast del modulo NCBIWWW che permette di cercare una sequenza su un database (refseq_rna). blastn è una variante di blast che confronta sequenze di nucleotidi con un database di nucleotidi.\n",
        "\n",
        "La funzione restituisce un file XML che poi viene letto dalla funzione read del modulo NCBIXML, che usa un parser interno.\n",
        "\n",
        "Il record che restituisce contiene un valore E-value che è una sorta di p-value (indica la confidence dell'allineamento). Se è sopra il valore soglia di 10^(-6) la funzione restituisce True\n",
        "\n",
        "Ho usato try ed except in caso di eventuali errori durante l'allineamento"
      ],
      "metadata": {
        "id": "W4R4IDWjbOkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verifica_sequenza_blast(seq):\n",
        "    try:\n",
        "        result_handle = NCBIWWW.qblast(\n",
        "            program=\"blastn\",\n",
        "            database=\"refseq_rna\",\n",
        "            sequence=seq\n",
        "        )\n",
        "\n",
        "        blast_records = NCBIXML.read(result_handle)\n",
        "\n",
        "        # Controlla se ci sono match con E-value < 1e-6\n",
        "        for alignment in blast_records.alignments:\n",
        "            for hsp in alignment.hsps:\n",
        "                if hsp.expect < 1e-6:\n",
        "                    return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante l'esecuzione di BLAST: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "bH8egE8Vbj_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Variabili\n",
        "Qui ho raccolto le variabili di score e posizionali per modificarle più agevolmente"
      ],
      "metadata": {
        "id": "wUwiVSATd4Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VARIABILI SCORE\n",
        "score_tatabox = 3\n",
        "score_inr = 2\n",
        "score_cpg = 1\n",
        "score_kozak = 2\n",
        "score_gc = 1\n",
        "score_codon = 1\n",
        "\n",
        "#SCORE SOGLIA\n",
        "soglia = 5\n",
        "\n",
        "#VARIABILI POSIZIONALI\n",
        "inizio_tatabox = -40\n",
        "fine_tatabox = -20\n",
        "inizio_inr = -10\n",
        "fine_inr = 10\n",
        "inizio_cpg = -3000\n",
        "inizio_kozak = -10\n",
        "fine_kozak = 10"
      ],
      "metadata": {
        "id": "HPjyYRHyd-Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Richiamo funzioni e assegnazione score\n",
        "Itero su ogni orf nell'oggetto generatore creato da orf_iter sulla stringa contenente la sequenza.\n",
        "\n",
        "Per prima cosa vengono eliminate le sequenze più piccole di 150bp, con continue l'iterazione corrente viene saltata.\n",
        "\n",
        "\n",
        "Poi creo la variabile score e assegno lo score inziale di 0\n",
        "\n",
        "A questo punto creo una sottosequenza che inizia 35 codoni prima dell'inizio dell'orf e finisce dopo 10 codoni (25 codoni prima dell'inizio dell'orf). Le variabili posizionali si possono modificare sopra.\n",
        "\n",
        "Se c'è il tatabox (la funzione tatabox() restituisce V o F), lo score viene aumentato di 3 (modificabile sopra).\n",
        "\n",
        "Viene fatta una cosa simile con tutti i sensori di segnale facendo attenizone a non andare out of bound con alcuni sensori, come l'inr. In quel caso viene aggiunto un controllo che in realtà dovrebbe esserci anche con altri sensori di segnale dato che potrebbe capitare un ATG a inizio sequenza\n",
        "\n",
        "I sensori di contenuto sono propri della sequenza, io qui ho creato una sottosequenza in questo modo\n",
        "\n",
        "\n",
        "```\n",
        "subseq = str(seq[orf.span()[0]:orf.span()[1]])\n",
        "```\n",
        "\n",
        "ma si può usare anche il metodo `.group()` che restituisce direttamente la sequenza.\n",
        "\n",
        "Infine, se lo score supera la soglia, viene aggiunto il valore True alla colonna \"Coding\" del df results tramite `results.loc[len(results)-1, 'Coding'] = True`.\n",
        "\n",
        "Poi viene chiamata la funzione `verifica_sequenza_blast()` e se la sequenza è codificante viene aggiunto il valore true alla colonna \"BLAST\" del df results in modo simile\n",
        "\n",
        "Infine vengono filtrate e stampate solo le orf codificanti e verificate su blast"
      ],
      "metadata": {
        "id": "R7LqaGoieFI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#inizio analisi\n",
        "for orf in orf_iter(str(seq)):\n",
        "  # FILTRAGGIO PRELIMINARE\n",
        "    if orf.span()[1] - orf.span()[0] < 150:\n",
        "        continue\n",
        "    results.loc[len(results)] = [orf.span()[0], False, False]\n",
        "\n",
        "    #PARTE CODING\n",
        "    #inizializzo score\n",
        "    score = 0\n",
        "    #il tatabox si trova tra -35 e -25 prima dell'ATG iniziale\n",
        "    subseq = str(seq[orf.span()[0]+inizio_tatabox:orf.span()[0]+fine_tatabox])\n",
        "    if tatabox(subseq):\n",
        "        score = score + score_tatabox\n",
        "    subseq = str(seq[orf.span()[0]+inizio_inr:orf.span()[0]+fine_inr])\n",
        "    #l'inr si trova tra -10 e +10 attorno all'ATG iniziale\n",
        "    if inr(subseq):\n",
        "        score = score + score_inr\n",
        "    #solo se la sequenza inizia dopo 3000 basi\n",
        "    if orf.span()[0] > 3000:\n",
        "        subseq = str(seq[orf.span()[0]+inizio_cpg:orf.span()[0]])\n",
        "        #controllo se nelle 3000 basi precedenti c'è un'alta frequenza di CpG\n",
        "        if cpg(subseq, exp_cpg):\n",
        "            score = score + score_cpg\n",
        "    #il kozak si trova tra -10 e +10 attorno all'ATG iniziale\n",
        "    subseq = str(seq[orf.span()[0]+inizio_kozak:orf.span()[0]+fine_kozak])\n",
        "    if kozak(subseq):\n",
        "        score = score + score_kozak\n",
        "    #i sensori di contenuto si applicano alla sequenza da ATG a stop\n",
        "    subseq = str(seq[orf.span()[0]:orf.span()[1]])\n",
        "    if gc_content(subseq):\n",
        "        score = score + score_gc\n",
        "    subseq = str(seq[orf.span()[0]:orf.span()[1]])\n",
        "    if codon_freq(subseq):\n",
        "        score = score + score_codon\n",
        "    if score >= soglia:\n",
        "        results.loc[len(results)-1, 'Coding'] = True\n",
        "        #PARTE VERIFICA BLAST\n",
        "        print(f'Controllo se la sequenza in posizione {orf.span()} è verificata su BLAST')\n",
        "        if verifica_sequenza_blast(subseq):\n",
        "            print(f'La sequenza in posizione {orf.span()} è verificata su BLAST')\n",
        "            results.loc[len(results)-1, 'BLAST'] = True\n",
        "\n",
        "#filtra solo le ORF codificanti\n",
        "cod = results[results['Coding'] == True]\n",
        "print(cod)\n",
        "\n",
        "#filtra solo le ORF codificanti verificate su BLAST\n",
        "ver = results[results['BLAST'] == True]\n",
        "print(ver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2EKk1IqeWOp",
        "outputId": "63a4d8fd-017f-4fec-c693-a47e54abccf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Controllo se la sequenza in posizione (768638, 768791) è verificata su BLAST\n",
            "Controllo se la sequenza in posizione (2143279, 2143573) è verificata su BLAST\n",
            "La sequenza in posizione (2143279, 2143573) è verificata su BLAST\n",
            "Controllo se la sequenza in posizione (2301612, 2301846) è verificata su BLAST\n",
            "La sequenza in posizione (2301612, 2301846) è verificata su BLAST\n",
            "Controllo se la sequenza in posizione (2357000, 2357276) è verificata su BLAST\n",
            "La sequenza in posizione (2357000, 2357276) è verificata su BLAST\n",
            "       ORFpos  Coding  BLAST\n",
            "1363   768638    True  False\n",
            "3751  2143279    True   True\n",
            "4029  2301612    True   True\n",
            "4158  2357000    True   True\n",
            "       ORFpos  Coding  BLAST\n",
            "3751  2143279    True   True\n",
            "4029  2301612    True   True\n",
            "4158  2357000    True   True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Salvataggio risultati su pickle\n",
        "Qui viene scritto un file pickle con il df results"
      ],
      "metadata": {
        "id": "EhTrgTiylwwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeP8yalQXqum"
      },
      "outputs": [],
      "source": [
        "# SALVATAGGIO DEI RISULTATI SU FILE\n",
        "with open(f\"group_{group_id}_results.pickle\", \"wb\") as f:\n",
        "\tpickle.dump(results, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
